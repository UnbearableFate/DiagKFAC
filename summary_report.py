#!/usr/bin/env python3
"""
ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆè„šæœ¬
ç”ŸæˆåŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„ç®€æ´æ‘˜è¦æŠ¥å‘Š
"""

import csv
import argparse

def generate_summary_report(csv_file: str = 'training_analysis_results.csv'):
    """
    ç”Ÿæˆç»¼åˆåˆ†ææ‘˜è¦æŠ¥å‘Š
    """
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            data = list(reader)
        
        print("=" * 80)
        print(" " * 25 + "è®­ç»ƒåˆ†æç»¼åˆæŠ¥å‘Š")
        print("=" * 80)
        
        # æŒ‰è®­ç»ƒæ—¶é—´æ’åºçš„æ‘˜è¦è¡¨æ ¼
        print("\n=== å®Œæ•´æ€§èƒ½å¯¹æ¯”è¡¨ ===")
        print(f"{'ä¼˜åŒ–å™¨ç»„åˆ':15} {'æ—¶é—´(s/epoch)':>12} {'å†…å­˜(GB)':>10} {'æœ€ç»ˆå‡†ç¡®ç‡(%)':>12} {'æ¨èEpochs':>10} {'é€Ÿåº¦æ¯”':>8}")
        print("-" * 75)
        
        # è¿‡æ»¤æœ‰æ—¶é—´æ•°æ®çš„è®°å½•å¹¶æŒ‰æ—¶é—´æ’åº
        time_data = [row for row in data if float(row.get('average_time_per_epoch', 0)) > 0]
        time_data.sort(key=lambda x: float(x['average_time_per_epoch']))
        
        for row in time_data:
            optimizer = row['optimizer_preconditioner']
            time_per_epoch = float(row['average_time_per_epoch'])
            memory = float(row['average_memory_gb'])
            final_acc = float(row['average_final_accuracy'])
            epochs = int(row['recommended_epochs'])
            speedup = float(row['speedup_ratio'])
            
            acc_str = f"{final_acc:.1f}" if final_acc > 0 else "N/A"
            
            print(f"{optimizer:15} {time_per_epoch:10.6f}   {memory:8.4f}   {acc_str:>10}   {epochs:8d}   {speedup:6.2f}x")
        
        # ç»Ÿè®¡æ‘˜è¦
        print(f"\n=== ç»Ÿè®¡æ‘˜è¦ ===")
        if time_data:
            fastest = min(time_data, key=lambda x: float(x['average_time_per_epoch']))
            slowest = max(time_data, key=lambda x: float(x['average_time_per_epoch']))
            
            print(f"æœ€å¿«ä¼˜åŒ–å™¨: {fastest['optimizer_preconditioner']} ({float(fastest['average_time_per_epoch']):.6f} ç§’/epoch)")
            print(f"æœ€æ…¢ä¼˜åŒ–å™¨: {slowest['optimizer_preconditioner']} ({float(slowest['average_time_per_epoch']):.6f} ç§’/epoch)")
            print(f"é€Ÿåº¦å·®å¼‚: {float(slowest['average_time_per_epoch']) / float(fastest['average_time_per_epoch']):.2f}x")
            
            # å†…å­˜ä½¿ç”¨åˆ†æ
            min_memory = min(time_data, key=lambda x: float(x['average_memory_gb']))
            max_memory = max(time_data, key=lambda x: float(x['average_memory_gb']))
            
            print(f"\næœ€ä½å†…å­˜: {min_memory['optimizer_preconditioner']} ({float(min_memory['average_memory_gb']):.4f} GB)")
            print(f"æœ€é«˜å†…å­˜: {max_memory['optimizer_preconditioner']} ({float(max_memory['average_memory_gb']):.4f} GB)")
            print(f"å†…å­˜å·®å¼‚: {float(max_memory['average_memory_gb']) / float(min_memory['average_memory_gb']):.2f}x")
        
        # å‡†ç¡®ç‡åˆ†æ
        accuracy_data = [row for row in data if float(row.get('average_final_accuracy', 0)) > 0]
        if accuracy_data:
            print(f"\n=== å‡†ç¡®ç‡åˆ†æ ===")
            best_acc = max(accuracy_data, key=lambda x: float(x['average_final_accuracy']))
            worst_acc = min(accuracy_data, key=lambda x: float(x['average_final_accuracy']))
            
            print(f"æœ€ä½³å‡†ç¡®ç‡: {best_acc['optimizer_preconditioner']} ({float(best_acc['average_final_accuracy']):.2f}%)")
            print(f"æœ€å·®å‡†ç¡®ç‡: {worst_acc['optimizer_preconditioner']} ({float(worst_acc['average_final_accuracy']):.2f}%)")
            print(f"å‡†ç¡®ç‡å·®å¼‚: {float(best_acc['average_final_accuracy']) - float(worst_acc['average_final_accuracy']):.2f}ä¸ªç™¾åˆ†ç‚¹")
            
            # æ€§ä»·æ¯”åˆ†æï¼ˆå‡†ç¡®ç‡/æ—¶é—´ï¼‰
            print(f"\n=== TOP 3 æ€§ä»·æ¯” (å‡†ç¡®ç‡/æ—¶é—´) ===")
            efficiency_data = []
            for row in accuracy_data:
                acc = float(row['average_final_accuracy'])
                time = float(row['average_time_per_epoch'])
                efficiency = acc / time
                efficiency_data.append((row['optimizer_preconditioner'], efficiency, acc, time))
            
            efficiency_data.sort(key=lambda x: x[1], reverse=True)
            for i, (name, eff, acc, time) in enumerate(efficiency_data[:3], 1):
                print(f"{i}. {name:15}: {eff:6.3f} ({acc:5.2f}% / {time:6.6f}s)")
        
        # æ¨èå»ºè®®
        print(f"\n=== ä½¿ç”¨å»ºè®® ===")
        if accuracy_data:
            best_overall = max(accuracy_data, key=lambda x: float(x['average_final_accuracy']))
            print(f"ğŸ† æœ€ä½³å‡†ç¡®ç‡: {best_overall['optimizer_preconditioner']} - è¿½æ±‚æœ€é«˜æ€§èƒ½æ—¶ä½¿ç”¨")
            
        if time_data:
            fastest_optimizer = min(time_data, key=lambda x: float(x['average_time_per_epoch']))
            print(f"âš¡ æœ€å¿«è®­ç»ƒ: {fastest_optimizer['optimizer_preconditioner']} - å¿«é€Ÿå®éªŒæˆ–èµ„æºå—é™æ—¶ä½¿ç”¨")
            
            lowest_memory = min(time_data, key=lambda x: float(x['average_memory_gb']))
            print(f"ğŸ’¾ æœ€ä½å†…å­˜: {lowest_memory['optimizer_preconditioner']} - å†…å­˜å—é™æ—¶ä½¿ç”¨")
        
        if accuracy_data and len(efficiency_data) > 0:
            best_efficiency = efficiency_data[0]
            print(f"âš–ï¸  æœ€ä½³å¹³è¡¡: {best_efficiency[0]} - å‡†ç¡®ç‡å’Œé€Ÿåº¦çš„æœ€ä½³å¹³è¡¡")
        
        print("=" * 80)
            
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {csv_file}")
        print("è¯·å…ˆè¿è¡Œ analyze_training_times_enhanced.py ç”Ÿæˆæ•°æ®")
    except Exception as e:
        print(f"é”™è¯¯: {e}")

def main():
    parser = argparse.ArgumentParser(description='ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š')
    parser.add_argument('--csv-file', default='training_analysis_results.csv',
                        help='è¾“å…¥çš„CSVæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    generate_summary_report(args.csv_file)

if __name__ == "__main__":
    main()
